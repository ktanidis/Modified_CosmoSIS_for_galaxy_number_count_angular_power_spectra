; This run shows an importance sampling process.
; Importance sampling lets you generate approximate samples from
; a distribution when you only have samples from another, similar distribution

; One important example is adding additional data from new, consistent, data
; to an existing run, and that's what this example shows. In this case the
; original distribution P is the Planck likelihood, and the new distribution
; P' is Planck+CFHTLenS.  Rather than re-calculate the Planck likelihood
; to include in P' we use a flag to 

; Note that this is not a valid importance sampling since the 
; contours of Planck and CFHTLenS disagree too much to get a valid sample.
; See appendix B of Lewis & Bridle  (PhysRevD 66 103511) for a nice overview.


[runtime]
sampler = importance

[importance]
; The chain from which we sample.  This is expected to have the standard cosmosis
; parameter name header line, which is pretty easy to construct
input = examples/input_d.txt

; The frequency at which we stop and save output.  Importance sampling
; is embarrassingly parallel, so this should not be so small that synchronizing the
; processors every nstep samples is not a significant slowdown.
; That is - ideally nstep should be quite a few times the number of processors.
nstep = 20

; In the case where you want to importance sample to include additional
; data onto a chain, you can set this to True to include the original likelihood
; into the new one, so that we need only calculate the CFHTLenS likelihood and
; not the Planck one too, which we just re-use.
add_to_likelihood = T

[output]
filename=example_d.txt
format=text


; The rest of this pipeline mirrors demo 6, which calculates the CFHTLenS likelihood.

[pipeline]
modules = consistency camb halofit extrapolate_power load_nz shear_shear 2pt cfhtlens
values = examples/values_d.ini

likelihoods = cfhtlens
extra_output = cosmological_parameters/sigma_8

; We can get a little more output during the run by setting some values
quiet=F
timing=F
debug=F

[consistency]
file = cosmosis-standard-library/utility/consistency/consistency_interface.py


[camb]
file = cosmosis-standard-library/boltzmann/camb/camb.so
mode=all
lmax=2500
feedback=0

[halofit]
file = cosmosis-standard-library/boltzmann/halofit/halofit_module.so

[extrapolate_power]
file=cosmosis-standard-library/boltzmann/extrapolate/extrapolate_power.py
kmax=500.0

; This is an example of a very simple module - it simple loads in 
; a file once at the start when setting up and supplies fixed data
; when executed.
[load_nz]
file = cosmosis-standard-library/number_density/load_nz/load_nz.py
filepath = cosmosis-standard-library/likelihood/cfhtlens/combined_nz.txt

; This module uses the Limber approximation to compute shear-shear C_ell
; given the shear kernel (which is derived from the number density and 
; from geometry)
[shear_shear]
file = cosmosis-standard-library/shear/spectra/interface.so
ell_min = 20.0
ell_max = 10000.0
n_ell = 220
intrinsic_alignments=F
matter_spectra=F


;This Nicaea code converts C_ell into xi(theta).
;It is fast and accurate but requires a high ell_max, as shown above
[2pt]
file = cosmosis-standard-library/shear/cl_to_xi_nicaea/nicaea_interface.so


; The CFHTLens likelihood
[cfhtlens]
file = cosmosis-standard-library/likelihood/cfhtlens/cfhtlens_interface.py

; The consistency module translates between our chosen parameterization
; ; and any other that modules in the pipeline may want (e.g. camb)
; [consistency]
; file = cosmosis-standard-library/utility/consistency/consistency_interface.py

